# –û—Å–Ω–æ–≤–Ω–æ–π —Å–∫—Ä–∏–ø—Ç –∞–≥–µ–Ω—Ç–∞

from addedFunc import sendMessageToYandexGPT
from addedFunc import get_html
from addedFunc import ErrorHandler
from bs4 import BeautifulSoup
import requests
import json
import re





# –≠—Ç–∞–ø—ã —Ä–∞–±–æ—Ç—ã:
# 1. –ü–æ–ª—É—á–µ–Ω–∏–µ:
#   * –¢–ó –≤ –≤–∏–¥–µ —Ç–µ–∫—Å—Ç–∞ –ø–æ –ø—É–Ω–∫—Ç–∞–º
#   * –°—Å—ã–ª–∫–∏ –Ω–∞ —Å–∞–π—Ç
#   * –¢–∞–±–ª–∏—á–∫–∏ —Å –Ω–∞–π–¥–µ–Ω–Ω—ã–º–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –¥–∞–Ω–Ω—ã–º–∏
# 2. –ê–≥–µ–Ω—Ç –ø—Ä–æ–±—É–µ—Ç –∑–∞–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É, –∏ –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π html
# 3. –ê–≥–µ–Ω—Ç —Ä–∞–∑–±–∏—Ä–∞–µ—Ç —Ç–∞–±–ª–∏—á–∫—É –∏ –¢–ó –≤ JSON —Ñ–æ—Ä–º–∞—Ç

# # ------------------

# print("–°—Ç–∞–¥–∏—è 2: –ü—Ä–æ–±—É–µ–º –∑–∞–π—Ç–∏ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É, –∏ –ø–æ–ª—É—á–∏—Ç—å –≤–∞–ª–∏–¥–Ω—ã–π html")

# url = "https://vodomirural.ru"
# html = get_html(url)
# print(html[:500])  # –í—ã–≤–µ–¥–µ–º –ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –∫–æ–Ω—Å–æ–ª—å
# # print(html) 
# if(len(html) < 500): print("–û—Ç–≤–µ—Ç –Ω–µ–≤–∞–ª–∏–¥–µ–Ω: –°–ª–∏—à–∫–æ–º –º–∞–ª–∞—è –¥–ª–∏–Ω–∞")
# # –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞ —Å–∞–π—Ç–∞—Ö —Å –∫—É—Ä–∞—Ç–æ—Ä–æ–º

# # ------------------

# 4. –ó–∞—Ö–æ–¥–∏–º –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É –ø–µ—Ä–≤–æ–≥–æ —Ç–æ–≤–∞—Ä–∞, –ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –µ–≥–æ –Ω–∞–∑–≤–∞–Ω–∏–µ, –∏–ª–∏ —á–∞—Å—Ç—å. –ï—Å–ª–∏ –¥–∞ - —Ç–æ –æ–∫, –∏–¥—ë–º –¥–∞–ª—å—à–µ
# –≠—Ç–æ –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ç–æ, —á—Ç–æ –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É —Ç–æ–≤–∞—Ä–∞ –º–æ–∂–Ω–æ –ø–æ–ø–∞—Å—Ç—å –±–µ–∑ –∑–∞—â–∏—Ç—ã

# url_first_item = "https://vodomirural.ru/catalog/vanny_stalnye_i_aksessuary_k_nim/33951/"

# –î–∞–Ω–Ω—ã–µ –∏–∑–≤–ª–µ—á—ë–Ω–Ω—ã–µ –∏–∑ —Ç–∞–±–ª–∏—Ü—ã, –Ω–∞–ø—Ä–∏–º–µ—Ä:
data_input_table = {
    "links": {
        "simple": [
            {
                "link": "https://vodomirural.ru/catalog/vanny_stalnye_i_aksessuary_k_nim/33951/",
                "name": "–í–∞–Ω–Ω–∞ —Å—Ç–∞–ª—å 1600—Ö700—Ö400–º–º antika –±–µ–ª—ã–π –≤ –∫–æ–º–ø–ª–µ–∫—Ç–µ —Å –Ω–æ–∂–∫–∞–º–∏ –í–ò–ó –≤ –ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥–µ",
                "price": "10 320",
                "brand": "–êntika",
                "inStock": True    
            }
        ]
    },
    "search_requests": []
}
# TODO: –ü–æ—Ç–æ–º –¥–æ–±–∞–≤–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É, —á—Ç–æ –±—ã –æ–Ω –∏—Å–∫–∞–ª –Ω–µ –ø–æ–ª–Ω—ã–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ–º –ø–æ–¥—Å—Ç—Ä–æ–∫–∏ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞ –ø—Ä–∏ –ø—Ä–æ–≤–µ—Ä–∫–µ, –∞ —á–∞—Å—Ç–∏—á–Ω—ã–º
# –≠—Ç–æ –∫–æ–≥–¥–∞ –Ω–∞–ø–∏—à—É —Ç–∞–∫—É—é —Ç—É–∫—É –¥–ª—è price

first_item_link = data_input_table["links"]["simple"][0]["link"]
# print(first_item_link)
html = get_html(first_item_link)
print(html[:500])

text_includes = data_input_table["links"]["simple"][0]["name"]
if text_includes in html:
    print("üü¢ –ü–æ–¥—Å—Ç—Ä–æ–∫–∞ –Ω–∞–π–¥–µ–Ω–∞!")
else:
    print("üü† –ü–æ–¥—Å—Ç—Ä–æ–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.")
    raise ErrorHandler("–ü—Ä–∏ –æ—Ç–∫—Ä—ã—Ç–∏–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã 1 —Ç–æ–≤–∞—Ä–∞, –Ω–∞ –Ω–µ–π –Ω–µ –±—ã–ª–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–∞–∑–≤–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–∞", "4-1")



def find_contexts(text: str, substring: str, context_size: int = 300) -> list[str]:
    """
    –ù–∞—Ö–æ–¥–∏—Ç –≤—Å–µ –≤—Ö–æ–∂–¥–µ–Ω–∏—è `substring` –≤ `text` –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫
    –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–≤ (–ø–æ `context_size` —Å–∏–º–≤–æ–ª–æ–≤ –¥–æ –∏ –ø–æ—Å–ª–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è).
    –ï—Å–ª–∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç—ã –ø–µ—Ä–µ–∫—Ä—ã–≤–∞—é—Ç—Å—è ‚Äî –æ–±—ä–µ–¥–∏–Ω—è–µ—Ç –∏—Ö.
    """
    results = []
    substring = re.escape(substring)  # —ç–∫—Ä–∞–Ω–∏—Ä—É–µ–º —Å–ø–µ—Ü—Å–∏–º–≤–æ–ª—ã
    matches = list(re.finditer(substring, text, flags=re.IGNORECASE))

    for match in matches:
        start = max(0, match.start() - context_size)
        end = min(len(text), match.end() + context_size)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –ø–µ—Ä–µ—Å–µ–∫–∞–µ—Ç—Å—è –ª–∏ —Å —É–∂–µ –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º
        if results and start <= results[-1][1]:
            # –æ–±—ä–µ–¥–∏–Ω—è–µ–º —Å –ø—Ä–µ–¥—ã–¥—É—â–∏–º —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–º
            prev_start, prev_end = results[-1]
            results[-1] = (prev_start, max(prev_end, end))
        else:
            results.append((start, end))

    # —Ñ–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –∫—É—Å–∫–∏ —Ç–µ–∫—Å—Ç–∞
    contexts = [text[s:e] for s, e in results]
    return contexts


# substring = "Makita"
substring_brand = data_input_table["links"]["simple"][0]["brand"]
substring_name = data_input_table["links"]["simple"][0]["name"]

# found = find_contexts(html, substring)
# # for i, ctx in enumerate(found, 1):
# #     print(f"\n=== –§—Ä–∞–≥–º–µ–Ω—Ç {i} ===")
# #     print(ctx)

# # print(found[0])

# prompt = f"""
# –û—Ç–ø—Ä–∞–≤–ª—è—é —Ç–µ–±–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç html –∫–æ–¥–∞. –ö–æ–Ω–∫—Ä–µ—Ç–Ω–æ –∏–∑ —ç—Ç–æ–≥–æ –ø—Ä–∏–º–µ—Ä–∞ –º—ã –∏–∑–≤–ª–µ–∫–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ "{substring}", 
# –Ω–æ —Ç–µ–±–µ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø—Ä–∏–º–µ—Ä, —á—Ç–æ –±—ã –æ–Ω —Ä–∞–±–æ—Ç–∞–ª –∏ —Å –¥—Ä—É–≥–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏. 
# –í –æ—Ç–≤–µ—Ç–µ –Ω–∞–ø–∏—à–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—É—Ç—å —Å–µ–ª–µ–∫—Ç–æ—Ä–æ–≤, –ø–æ –∫–æ—Ç–æ—Ä–æ–º—É –º–æ–∂–Ω–æ –∏–∑–≤–ª–µ—á—å —Ç–∞–∫–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –∏–∑ html —Å—Ç—Ä–∞–Ω–∏—Ü—ã.
# {found[0]}
# """

# print("_____________________________________")
# print("–ü–æ—Å—ã–ª–∞–µ–º –∑–∞–ø—Ä–æ—Å")
# print(prompt)

# # response = sendMessageToYandexGPT(prompt)

# # –ù—É–∂–Ω–æ —Å–¥–µ–ª–∞—Ç—å –∞–Ω–∞–ª–æ–≥, –Ω–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º DOM –ø–æ–ª—É—á–µ–Ω–Ω–æ–π —Å—Ç—Ä–∞–Ω–∏—Ü—ã
# # –ò –ø—Ä–æ–ø–∏—Å–∞—Ç—å —Ä–∞–±–æ—Ç—É —Å –±–∏–±–ª–∏–æ—Ç–µ–∫–æ–π cheerio







# def get_css_path(element):
#     """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞."""
#     path = []
#     while element and element.name:
#         selector = element.name
#         # –ï—Å–ª–∏ –µ—Å—Ç—å id ‚Äî —ç—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ, –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
#         if element.has_attr("id"):
#             selector = f"#{element['id']}"
#             path.append(selector)
#             break
#         # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–ª–∞—Å—Å ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º
#         elif element.has_attr("class"):
#             selector += "." + ".".join(element["class"])
#         # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Å —Ç–µ–º –∂–µ —Ç–µ–≥–æ–º ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º nth-of-type
#         siblings = element.find_previous_siblings(element.name)
#         if siblings:
#             selector += f":nth-of-type({len(siblings)+1})"
#         path.append(selector)
#         element = element.parent
#     return " > ".join(reversed(path))

# def find_text_selector(html: str, text: str, exact: bool = False):
#     """–ù–∞—Ö–æ–¥–∏—Ç CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞—â–µ–≥–æ –∑–∞–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç."""
#     soup = BeautifulSoup(html, "html.parser")
#     if exact:
#         target = soup.find(lambda tag: tag.string and tag.string.strip() == text)
#     else:
#         target = soup.find(lambda tag: tag.string and text in tag.string)
#     if not target:
#         return None
#     return get_css_path(target)

# selector = find_text_selector(html, substring_name)
# print(selector)

# # a.catalog-element-brand img






from bs4 import BeautifulSoup

def get_css_path(element):
    """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä–∞ –¥–ª—è –¥–∞–Ω–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞."""
    path = []
    while element and element.name:
        selector = element.name

        # –ï—Å–ª–∏ —É —ç–ª–µ–º–µ–Ω—Ç–∞ –µ—Å—Ç—å ID ‚Äî —ç—Ç–æ —É–Ω–∏–∫–∞–ª—å–Ω–æ
        if element.has_attr("id"):
            selector = f"#{element['id']}"
            path.append(selector)
            break

        # –ï—Å–ª–∏ –µ—Å—Ç—å –∫–ª–∞—Å—Å(—ã)
        elif element.has_attr("class"):
            selector += "." + ".".join(element["class"])

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä—è–¥–æ–∫ —ç–ª–µ–º–µ–Ω—Ç–∞ —Å—Ä–µ–¥–∏ —Å–∏–±–ª–∏–Ω–≥–æ–≤
        siblings = element.find_previous_siblings(element.name)
        if siblings:
            selector += f":nth-of-type({len(siblings) + 1})"

        path.append(selector)
        element = element.parent

    return " > ".join(reversed(path))


def find_text_selector(html: str, text: str, exact: bool = False):
    """–ù–∞—Ö–æ–¥–∏—Ç CSS-—Å–µ–ª–µ–∫—Ç–æ—Ä —ç–ª–µ–º–µ–Ω—Ç–∞, —Å–æ–¥–µ—Ä–∂–∞—â–µ–≥–æ –∑–∞–¥–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ –≤ –∞—Ç—Ä–∏–±—É—Ç–∞—Ö."""
    soup = BeautifulSoup(html, "html.parser")

    # –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –≤—Å–µ–º —ç–ª–µ–º–µ–Ω—Ç–∞–º –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ
    for el in soup.find_all(True):  # True ‚Äî –∑–Ω–∞—á–∏—Ç –≤—Å–µ —Ç–µ–≥–∏
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—Å—Ç –≤–Ω—É—Ç—Ä–∏ —ç–ª–µ–º–µ–Ω—Ç–∞
        if el.string and ((text == el.string.strip()) if exact else (text in el.string)):
            return get_css_path(el)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –∞—Ç—Ä–∏–±—É—Ç—ã
        for attr_val in el.attrs.values():
            if isinstance(attr_val, list):
                attr_val = " ".join(attr_val)
            if isinstance(attr_val, str) and (text in attr_val if not exact else text == attr_val.strip()):
                return get_css_path(el)

    return None

# selector = find_text_selector(html, substring_name)
selector = find_text_selector(html, substring_brand)
print(selector)

### –ö–æ—Ä–æ—á–µ, —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –≤—ã–≤–æ–¥–∏—Ç –º—É—Å–æ—Ä–Ω—ã–µ css –ø—É—Ç–∏
### –í —Ü–µ–ª–æ–º, –Ω–∞ —ç—Ç–æ–º –ø–æ–∫–∞ —á—Ç–æ –º–æ–∂–Ω–æ –æ—Å—Ç–∞–Ω–æ–≤–∏—Ç—å—Å—è
### –ò —á–∏—Å—Ç–∏—Ç—å –∏—Ö —É–∂–µ –ø–æ–∑–∂–µ (–ø–æ–∑–∂–µ –ø—Ä–æ–ø–∏—Å–∞—Ç—å, –∏–ª–∏ –ø–æ–∑–∂–µ –≤ –∫–æ–¥–µ —á–∏—Å—Ç–∏—Ç—å)